{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 1: Particionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nÍndices de Validación Simple para tic-tac-toe: \n\tTrain: [2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 23, 24, 25, 27, 29, 30, 31]...\n\tTest: [0, 1, 9, 12, 17, 18, 19, 20, 21, 22, 26, 28, 32, 36, 39, 41, 45, 48, 50, 54]...\n\nÍndices de Validación cruzada para tic-tac-toe: \n\tTrain: [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24]...\n\tTest: [0, 4, 14, 19, 22, 25, 29, 42, 48, 50, 54, 63, 80, 82, 94, 96, 99, 101, 104, 106]...\n\tTrain: [0, 1, 2, 4, 5, 6, 7, 8, 9, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]...\n\tTest: [3, 10, 11, 13, 30, 41, 70, 81, 83, 84, 86, 90, 102, 110, 120, 124, 155, 157, 164, 165]...\n\tTrain: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 22, 23]...\n\tTest: [6, 15, 18, 21, 26, 27, 28, 31, 33, 38, 43, 44, 47, 49, 52, 60, 61, 66, 73, 75]...\n\tTrain: [0, 3, 4, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25]...\n\tTest: [1, 2, 5, 9, 12, 20, 32, 35, 39, 46, 53, 56, 57, 72, 78, 85, 95, 100, 107, 125]...\n\tTrain: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21]...\n\tTest: [7, 16, 23, 24, 34, 51, 55, 59, 64, 65, 68, 69, 74, 76, 79, 88, 89, 91, 103, 105]...\n\tTrain: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21]...\n\tTest: [8, 17, 36, 37, 40, 45, 58, 62, 67, 71, 93, 97, 98, 109, 112, 113, 119, 121, 129, 130]...\n\nÍndices de Validación Bootstrap para tic-tac-toe: \n\tTrain: [0, 2, 2, 3, 4, 4, 5, 5, 6, 6, 6, 9, 9, 11, 11, 11, 12, 12, 13, 14]...\n\tTest: [1, 7, 8, 10, 18, 22, 24, 27, 29, 30, 31, 33, 35, 36, 38, 42, 46, 47, 51, 53]...\n\n\n\n\nÍndices de Validación Simple para balloons: \n\tTrain: [0, 1, 3, 5, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n\tTest: [2, 4, 6, 8, 9, 15]\n\nÍndices de Validación cruzada para balloons: \n\tTrain: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19]\n\tTest: [4, 5, 14, 18]\n\tTrain: [1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18]\n\tTest: [0, 2, 11, 19]\n\tTrain: [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]\n\tTest: [6, 8, 15]\n\tTrain: [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19]\n\tTest: [1, 10, 12]\n\tTrain: [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19]\n\tTest: [3, 9, 17]\n\tTrain: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19]\n\tTest: [7, 13, 16]\n\nÍndices de Validación Bootstrap para balloons: \n\tTrain: [0, 3, 3, 3, 3, 4, 6, 9, 10, 10, 12, 12, 14, 15, 16, 16, 17, 18, 19, 19]\n\tTest: [1, 2, 5, 7, 8, 11, 13]\n"
     ]
    }
   ],
   "source": [
    "from Datos import Datos\n",
    "from ValidacionBootstrap import ValidacionBootstrap\n",
    "from ValidacionCruzada import ValidacionCruzada\n",
    "from ValidacionSimple import ValidacionSimple\n",
    "\n",
    "balloons = Datos('ConjuntosDatos/balloons.data')\n",
    "tic_tac_toe = Datos('ConjuntosDatos/tic-tac-toe.data')\n",
    "\n",
    "validaciones = [ValidacionSimple(70), ValidacionCruzada(6), ValidacionBootstrap()]\n",
    "\n",
    "for val in validaciones:\n",
    "    val.creaParticiones(tic_tac_toe.datos)\n",
    "    \n",
    "    print(\"\\nÍndices de \", val.nombre_estrategia, \" para tic-tac-toe: \", sep='')\n",
    "    for particion in val.particiones:\n",
    "        print(\"\\tTrain: \", sorted(particion.indicesTrain)[:20], \"...\", sep='')\n",
    "        print(\"\\tTest: \", sorted(particion.indicesTest)[:20], \"...\", sep='')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "for val in validaciones:\n",
    "    val.creaParticiones(balloons.datos)\n",
    "    \n",
    "    print(\"\\nÍndices de \", val.nombre_estrategia, \" para balloons: \", sep='')\n",
    "    for particion in val.particiones:\n",
    "        print(\"\\tTrain: \", sorted(particion.indicesTrain), sep='')\n",
    "        print(\"\\tTest: \", sorted(particion.indicesTest), sep='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripcción de los índices de train y test\n",
    "\n",
    "Hemos imprimido los índices ordenados para que sean más fáciles de analizar a simple vista.\n",
    "\n",
    "Vemos que para validación simple, cogemos todos los índices y aleatoriamente tomamos un porcentaje para test y el resto son de test.\n",
    "\n",
    "Para validación cruzados vemos cómo se crean las 6 particiones (folds) que hemos especificado, y que en cada una de las particiones los índices de test son diferentes hasta completar todos los índices. Los índices de train de cada partición son los que no hemos tomado para test.\n",
    "\n",
    "En validación por Bootstrap tomamos como train tantos índices aleatorios como datos haya, permitiendo que haya repeticiones, y los datos de test son aquellos índices que no hemos cogido.\n",
    "\n",
    "\n",
    "## Ventajas/desventajas de cada una de las validaciones\n",
    "\n",
    "Validación simple es claramente el más fácil de entender e implementar y si se dividen los datos aleatoriamente funciona bien.\n",
    "\n",
    "Validación cruzada al hacer más particiones dará una tasa de fallos más realista, pero a costa de tener que realizar múltiples veces el proceso de entrenamiento, haciendo que el tiempo de validación aumente proporcionalmente al número de folds.\n",
    "\n",
    "El principal inconveniente de Bootstrap es que elegimos para train varias veces los mismos ejemplos, haciendo que la tasa de error esté subestimada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2: Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n Validación Simple sin corrección de Laplace:\n\t                               tasa de error                  desviación típica del error   \n\tballoons                       0.000000                       0.000000                      \n\ttic-tac-toe                    0.267361                       0.442582                      \n\tgerman                         0.220000                       0.414246                      \n\n Validación Simple con corrección de Laplace:\n\t                               tasa de error                  desviación típica del error   \n\tballoons                       0.166667                       0.372678                      \n\ttic-tac-toe                    0.291667                       0.454530                      \n\tgerman                         0.250000                       0.433013                      \n\n\n Validación cruzada sin corrección de Laplace:\n\t                               tasa de error                  desviación típica del error   \n\tballoons                       0.000000                       0.000000                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttic-tac-toe                    0.301670                       0.458983                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgerman                         0.259000                       0.438086                      \n\n Validación cruzada con corrección de Laplace:\n\t                               tasa de error                  desviación típica del error   \n\tballoons                       0.000000                       0.000000                      \n\ttic-tac-toe                    0.299582                       0.458075                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgerman                         0.252000                       0.434161                      \n\n\n Validación Bootstrap sin corrección de Laplace:\n\t                               tasa de error                  desviación típica del error   \n\tballoons                       0.000000                       0.000000                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttic-tac-toe                    0.276056                       0.447045                      \n\tgerman                         0.242667                       0.428695                      \n\n Validación Bootstrap con corrección de Laplace:\n\t                               tasa de error                  desviación típica del error   \n\tballoons                       0.111111                       0.314270                      \n\ttic-tac-toe                    0.289086                       0.453338                      \n\tgerman                         0.234043                       0.423399                      \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ClasificadorNaiveBayes import ClasificadorNaiveBayes\n",
    "\n",
    "german = Datos('ConjuntosDatos/german.data')\n",
    "nb = ClasificadorNaiveBayes()\n",
    "\n",
    "for val in validaciones:\n",
    "    format_header = \"\\t%-30s %-30s %-30s\"\n",
    "    format_cell = \"\\t%-30s %-30f %-30f\"\n",
    "    \n",
    "    print(\"\\n\\n\", val.nombre_estrategia, \"sin corrección de Laplace:\")\n",
    "    print(format_header % (\"\", \"tasa de error\", \"desviación típica del error\"))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, balloons, nb, aplicar_correccion_de_laplace=False)\n",
    "    print(format_cell % (\"balloons\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, tic_tac_toe, nb, aplicar_correccion_de_laplace=False)\n",
    "    print(format_cell % (\"tic-tac-toe\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, german, nb, aplicar_correccion_de_laplace=False)\n",
    "    print(format_cell % (\"german\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\", val.nombre_estrategia, \"con corrección de Laplace:\")\n",
    "    print(format_header % (\"\", \"tasa de error\", \"desviación típica del error\"))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, balloons, nb)\n",
    "    print(format_cell % (\"balloons\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, tic_tac_toe, nb)\n",
    "    print(format_cell % (\"tic-tac-toe\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, german, nb)\n",
    "    print(format_cell % (\"german\", tasa_de_error, np.std(errores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los resultados\n",
    "\n",
    "Vemos que para balloons la tasa de fallos es muy baja o nula. Esto es debido a que el número de datos es muy pequeño.\n",
    "\n",
    "Para tic-tac-toe y German vemos que con validación simple al aplicar la corrección de Laplace la tasa de aciertos mejora, mientras que para validación cruzada permanece prácticamente igual y para bootstrap empeora.\n",
    "\n",
    "En tic-tac-toe vemos que el porcentaje de errores para cualquiera de las validaciones está en torno a un 30%\n",
    "\n",
    "En los datos de German el porcentaje de errores es ligeramente menor, estando en torno a un 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 3: Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german:\n\tTasa de error con validación simple: 0.37666666666666665\n\tTasa de error con validación cruzada: 0.277\ntic-tac-toe:\n\tTasa de error con validación simple: 0.3055555555555556\n\tTasa de error con validación cruzada: 0.3246346555323591\n\n\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:385: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n  \"use the ColumnTransformer instead.\", DeprecationWarning)\n/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:385: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "for dataset in [german, tic_tac_toe]:\n",
    "    if dataset == german:\n",
    "        print(\"german:\")\n",
    "    else:\n",
    "        print(\"tic-tac-toe:\")\n",
    "    \n",
    "    # Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features). Hay DeprecationWarnings\n",
    "    encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
    "    X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
    "    \n",
    "    # Clases correspondientes a cada uno de los array de X\n",
    "    y = dataset.datos[:, -1]\n",
    "    \n",
    "    # Particiones del modo Validacion Simple\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Entrenamiento y clasificacion de X_test\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    errores = y_pred != y_test\n",
    "    tasa_de_error = sum(errores) / len(errores)\n",
    "    \n",
    "    print(\"\\tTasa de error con validación simple:\", tasa_de_error)\n",
    "    \n",
    "    # Particiones del modo Validacion Cruzada\n",
    "    kf = KFold(n_splits=6, shuffle=True)\n",
    "    \n",
    "    errores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "        \n",
    "        errores.append(y_pred != y_test)\n",
    "    \n",
    "    errores = list(itertools.chain.from_iterable(errores))\n",
    "    tasa_de_error = sum(errores) / len(errores)\n",
    "    print(\"\\tTasa de error con validación cruzada:\", tasa_de_error)\n",
    "\n",
    "print(\"\\n\" * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos hecho la mismas validaciones que en el apartado anterior y vemos que los porcentajes de error son muy similares a los que teníamos antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
