{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 1: Particionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ConjuntosDatos/balloons.data'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1bab801df593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mValidacionSimple\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mValidacionSimple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mballoons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ConjuntosDatos/balloons.data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtic_tac_toe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ConjuntosDatos/tic-tac-toe.data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nicolas/Documents/MasterII/FAA/P2/Datos.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nombreFichero)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnombreFichero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnombreFichero\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ConjuntosDatos/balloons.data'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from Datos import Datos\n",
    "from ValidacionBootstrap import ValidacionBootstrap\n",
    "from ValidacionCruzada import ValidacionCruzada\n",
    "from ValidacionSimple import ValidacionSimple\n",
    "\n",
    "balloons = Datos('ConjuntosDatos/balloons.data')\n",
    "tic_tac_toe = Datos('ConjuntosDatos/tic-tac-toe.data')\n",
    "\n",
    "validaciones = [ValidacionSimple(70), ValidacionCruzada(6), ValidacionBootstrap()]\n",
    "\n",
    "for val in validaciones:\n",
    "    val.creaParticiones(tic_tac_toe.datos)\n",
    "    \n",
    "    print(\"\\nÍndices de \", val.nombre_estrategia, \" para tic-tac-toe: \", sep='')\n",
    "    for particion in val.particiones:\n",
    "        print(\"\\tTrain: \", sorted(particion.indicesTrain)[:20], \"...\", sep='')\n",
    "        print(\"\\tTest: \", sorted(particion.indicesTest)[:20], \"...\", sep='')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "for val in validaciones:\n",
    "    val.creaParticiones(balloons.datos)\n",
    "    \n",
    "    print(\"\\nÍndices de \", val.nombre_estrategia, \" para balloons: \", sep='')\n",
    "    for particion in val.particiones:\n",
    "        print(\"\\tTrain: \", sorted(particion.indicesTrain), sep='')\n",
    "        print(\"\\tTest: \", sorted(particion.indicesTest), sep='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripcción de los índices de train y test\n",
    "\n",
    "Hemos imprimido los índices ordenados para que sean más fáciles de analizar a simple vista.\n",
    "\n",
    "Vemos que para validación simple, cogemos todos los índices y aleatoriamente tomamos un porcentaje para test y el resto son de test.\n",
    "\n",
    "Para validación cruzados vemos cómo se crean las 6 particiones (folds) que hemos especificado, y que en cada una de las particiones los índices de test son diferentes hasta completar todos los índices. Los índices de train de cada partición son los que no hemos tomado para test.\n",
    "\n",
    "En validación por Bootstrap tomamos como train tantos índices aleatorios como datos haya, permitiendo que haya repeticiones, y los datos de test son aquellos índices que no hemos cogido.\n",
    "\n",
    "\n",
    "## Ventajas/desventajas de cada una de las validaciones\n",
    "\n",
    "Validación simple es claramente el más fácil de entender e implementar y si se dividen los datos aleatoriamente funciona bien.\n",
    "\n",
    "Validación cruzada al hacer más particiones dará una tasa de fallos más realista, pero a costa de tener que realizar múltiples veces el proceso de entrenamiento, haciendo que el tiempo de validación aumente proporcionalmente al número de folds.\n",
    "\n",
    "El principal inconveniente de Bootstrap es que elegimos para train varias veces los mismos ejemplos, haciendo que la tasa de error esté subestimada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2: Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ClasificadorNaiveBayes'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-695788aa90d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mClasificadorNaiveBayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClasificadorNaiveBayes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgerman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ConjuntosDatos/german.data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ClasificadorNaiveBayes'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ClasificadorNaiveBayes import ClasificadorNaiveBayes\n",
    "\n",
    "german = Datos('ConjuntosDatos/german.data')\n",
    "nb = ClasificadorNaiveBayes()\n",
    "\n",
    "for val in validaciones:\n",
    "    format_header = \"\\t%-30s %-30s %-30s\"\n",
    "    format_cell = \"\\t%-30s %-30f %-30f\"\n",
    "    \n",
    "    print(\"\\n\\n\", val.nombre_estrategia, \"sin corrección de Laplace:\")\n",
    "    print(format_header % (\"\", \"tasa de error\", \"desviación típica del error\"))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, balloons, nb, aplicar_correccion_de_laplace=False)\n",
    "    print(format_cell % (\"balloons\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, tic_tac_toe, nb, aplicar_correccion_de_laplace=False)\n",
    "    print(format_cell % (\"tic-tac-toe\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, german, nb, aplicar_correccion_de_laplace=False)\n",
    "    print(format_cell % (\"german\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\", val.nombre_estrategia, \"con corrección de Laplace:\")\n",
    "    print(format_header % (\"\", \"tasa de error\", \"desviación típica del error\"))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, balloons, nb)\n",
    "    print(format_cell % (\"balloons\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, tic_tac_toe, nb)\n",
    "    print(format_cell % (\"tic-tac-toe\", tasa_de_error, np.std(errores)))\n",
    "    \n",
    "    errores, tasa_de_error = nb.validacion(val, german, nb)\n",
    "    print(format_cell % (\"german\", tasa_de_error, np.std(errores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los resultados\n",
    "\n",
    "Vemos que para balloons la tasa de fallos es muy baja o nula. Esto es debido a que el número de datos es muy pequeño.\n",
    "\n",
    "Para tic-tac-toe y German vemos que con validación simple al aplicar la corrección de Laplace la tasa de aciertos mejora, mientras que para validación cruzada permanece prácticamente igual y para bootstrap empeora.\n",
    "\n",
    "En tic-tac-toe vemos que el porcentaje de errores para cualquiera de las validaciones está en torno a un 30%\n",
    "\n",
    "En los datos de German el porcentaje de errores es ligeramente menor, estando en torno a un 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 3: Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'german' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-14b33da9119e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgerman\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtic_tac_toe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgerman\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"german:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'german' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "for dataset in [german, tic_tac_toe]:\n",
    "    if dataset == german:\n",
    "        print(\"german:\")\n",
    "    else:\n",
    "        print(\"tic-tac-toe:\")\n",
    "    \n",
    "    # Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features). Hay DeprecationWarnings\n",
    "    encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
    "    X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
    "    \n",
    "    # Clases correspondientes a cada uno de los array de X\n",
    "    y = dataset.datos[:, -1]\n",
    "    \n",
    "    # Particiones del modo Validacion Simple\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Entrenamiento y clasificacion de X_test\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    errores = y_pred != y_test\n",
    "    tasa_de_error = sum(errores) / len(errores)\n",
    "    \n",
    "    print(\"\\tTasa de error con validación simple:\", tasa_de_error)\n",
    "    \n",
    "    # Particiones del modo Validacion Cruzada\n",
    "    kf = KFold(n_splits=6, shuffle=True)\n",
    "    \n",
    "    errores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "        \n",
    "        errores.append(y_pred != y_test)\n",
    "    \n",
    "    errores = list(itertools.chain.from_iterable(errores))\n",
    "    tasa_de_error = sum(errores) / len(errores)\n",
    "    print(\"\\tTasa de error con validación cruzada:\", tasa_de_error)\n",
    "\n",
    "print(\"\\n\" * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos hecho la mismas validaciones que en el apartado anterior y vemos que los porcentajes de error son muy similares a los que teníamos antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
